{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate `contents.json` based on the `d2l-zh` repos, then manually copy and modify to `_modelules/*.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:50:55.838647Z",
     "start_time": "2021-04-19T17:50:53.866026Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tornado.web' has no attribute 'asynchronous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2ef37715d833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnotedown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m entry = '''    {\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/mu_notedown-2.0.1-py3.7.egg/notedown/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnotedown\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkdown_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/mu_notedown-2.0.1-py3.7.egg/notedown/notedown.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbjson\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnbconvert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExecutePreprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnbconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemplateExporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/nbconvert/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpostprocessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwriters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/nbconvert/postprocessors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# protect against unavailable tornado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mserve\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mServePostProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/nbconvert/postprocessors/serve.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mProxyHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;34m\"\"\"handler the proxies requests from a local prefix to a CDN\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/nbconvert/postprocessors/serve.py\u001b[0m in \u001b[0;36mProxyHandler\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mProxyHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m\"\"\"handler the proxies requests from a local prefix to a CDN\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mweb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;34m\"\"\"proxy a request to a CDN\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tornado.web' has no attribute 'asynchronous'"
     ]
    }
   ],
   "source": [
    "import notedown\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "entry = '''    {\n",
    "        \"title\":\"TITLE\",\n",
    "        \"day_break\":false,\n",
    "        \"book\":\"URL\",\n",
    "        \"slides\":[\"part-0.pdf\",0],\n",
    "        \"slides_video\":\"\",\n",
    "        \"notebook_video\":\"\",\n",
    "        \"qa_video\":\"\"\n",
    "    }'''\n",
    "\n",
    "\n",
    "book_repo = pathlib.Path('/Users/mli/repos/d2l-en')\n",
    "\n",
    "def get_toc(root):\n",
    "    \"\"\"return a list of files in the order defined by TOC\"\"\"\n",
    "    subpages = _get_subpages(root)\n",
    "    res = [root]\n",
    "    for fn in subpages:\n",
    "        res.extend(get_toc(fn))\n",
    "    return res\n",
    "\n",
    "def _get_subpages(input_fn):\n",
    "    \"\"\"read toc in input_fn, returns what it contains\"\"\"\n",
    "    subpages = []\n",
    "    reader = notedown.MarkdownReader()\n",
    "    with open(input_fn, 'r', encoding='UTF-8') as f:\n",
    "        nb = reader.read(f)\n",
    "    for cell in nb.cells:\n",
    "        if (cell.cell_type == 'code' and 'attributes' in cell.metadata and\n",
    "                'toc' in cell.metadata.attributes['classes']):\n",
    "            for l in cell.source.split('\\n'):\n",
    "                l = l.strip()\n",
    "                if not l.startswith(':'):\n",
    "                    fn = os.path.join(os.path.dirname(input_fn), l + '.md')\n",
    "                    if os.path.exists(fn):\n",
    "                        subpages.append(fn)\n",
    "    return subpages\n",
    "\n",
    "def _get_title(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            if l.startswith('#'): return l[1:].strip()\n",
    "\n",
    "entries = []\n",
    "notebooks = get_toc(str(book_repo/'index.md'))\n",
    "for nb in notebooks:\n",
    "    p = str(pathlib.Path(nb).relative_to(book_repo).with_suffix('.html'))\n",
    "    if 'index.md' in p: continue\n",
    "    title = _get_title(nb)\n",
    "    if not title: continue\n",
    "    entries.append(entry.replace('TITLE', title).replace('URL', p))\n",
    "\n",
    "with open('contents.json', 'w') as f:\n",
    "    f.write('[\\n' + ',\\n'.join(entries) + '\\n]\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T04:49:19.327917Z",
     "start_time": "2021-05-14T04:49:19.286976Z"
    }
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "import subprocess\n",
    "\n",
    "def extract_pdf(source, start_page, end_page, target):\n",
    "    source = pathlib.Path(source)\n",
    "    target = pathlib.Path(target)\n",
    "    if target.exists() and target.stat().st_mtime > source.stat().st_mtime:\n",
    "        return\n",
    "    pdf = PdfFileReader(str(source))\n",
    "    assert end_page > start_page\n",
    "    assert end_page <= pdf.getNumPages()\n",
    "    pdf_writer = PdfFileWriter()\n",
    "    for page in range(start_page, end_page):\n",
    "        pdf_writer.addPage(pdf.getPage(page))\n",
    "    with open('/tmp/tmp.pdf', 'wb') as out:\n",
    "        pdf_writer.write(out)\n",
    "    # compress pdf size\n",
    "    # refer to https://askubuntu.com/questions/113544/how-can-i-reduce-the-file-size-of-a-scanned-pdf-file\n",
    "    cmd = f'gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/prepress -dNOPAUSE  -dBATCH -sOutputFile={str(target)} /tmp/tmp.pdf'\n",
    "    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.PIPE)\n",
    "    stdout, _ = process.communicate()\n",
    "    if process.returncode != 0:\n",
    "        print(stdout.decode().splitlines())\n",
    "    print(f'Written {end_page-start_page} pages to {target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate all `_modules/part*.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T05:12:21.091701Z",
     "start_time": "2021-05-14T05:12:20.918810Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "pdf_dir = '/Users/mli/Google Drive/d2l-zh-v2-slides/'\n",
    "slides_dir = 'assets/pdfs/'\n",
    "notebooks_dir = 'assets/notebooks/'\n",
    "book_url = 'https://zh-v2.d2l.ai/'\n",
    "notebook_url = 'https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/'\n",
    "notbook_repo = '../d2l-zh-pytorch-slides/'\n",
    "video_url = 'https://www.bilibili.com/video/'\n",
    "cur_day = datetime.datetime(2021, 3, 19)\n",
    "\n",
    "titles = ['深度学习基础', '卷积神经网络', '计算机视觉', '循环神经网络', '注意力机制', '自然语言处理','优化算法',]\n",
    "holidays = [datetime.datetime(2021, m, d) for m, d in ((4,3),(4,4),(4,25),(5,1),(5,2),(5,8),(5,9),(6,12),(6,13))]\n",
    "slide_pages = {}\n",
    "\n",
    "for i, title in enumerate(titles):\n",
    "    p = pathlib.Path('_modules')\n",
    "    with (p/f'part_{i}.md').open('w') as f:\n",
    "        f.write(f'---\\ntitle: {title}\\n---\\n')\n",
    "        if not (p/f'part_{i}.json').exists():\n",
    "            contents = []\n",
    "        else:\n",
    "            contents = json.load((p/f'part_{i}.json').open('r'))\n",
    "        for entry in contents:\n",
    "            if entry['day_break']:\n",
    "                while True:\n",
    "                    if cur_day.weekday() == 6: # sun\n",
    "                        cur_day += datetime.timedelta(days=6)\n",
    "                    else:\n",
    "                        cur_day += datetime.timedelta(days=1)\n",
    "                    f.write(f'\\n{cur_day.month}月{cur_day.day}日\\n\\n')\n",
    "                    if cur_day not in holidays:\n",
    "                        break\n",
    "                    f.write(': **长假无课**{: .label .label-green }\\n')\n",
    "            # title\n",
    "            f.write(f': {entry[\"title\"]}\\n')\n",
    "            # html page\n",
    "            if 'book' in entry and entry['book']:\n",
    "                f.write(f'  : [<span class=\"iconfont icon-xiaoshuo-copy\"></span>]({book_url+entry[\"book\"]})\\n')\n",
    "            else:\n",
    "                f.write('  : &nbsp; \\n')\n",
    "            # pdf\n",
    "            pdf, page = entry['slides']\n",
    "            if page:\n",
    "                if pdf not in slide_pages:\n",
    "                    slide_pages[pdf] = [0,]\n",
    "                save_pdf = f'{slides_dir}part-{i}_{len(slide_pages[pdf])}.pdf'\n",
    "                cur_page = sum(slide_pages[pdf])\n",
    "                extract_pdf(pdf_dir+pdf, cur_page, cur_page+page, save_pdf)\n",
    "                slide_pages[pdf].append(page)\n",
    "                f.write(f'  : [<span class=\"iconfont icon-KeynoteOutline\"></span>]({save_pdf})\\n')\n",
    "            else:\n",
    "                f.write('  : &nbsp; \\n')\n",
    "\n",
    "            # notebook\n",
    "            write_notebook = False\n",
    "            if 'book' in entry and entry['book'] and  (not 'notebook' in  entry or entry['notebook']):\n",
    "                notebook_path = entry[\"book\"].replace('.html', '.ipynb')\n",
    "                notebook_file = notbook_repo + notebook_path\n",
    "                notebook_output = pathlib.Path(notebooks_dir + notebook_path).with_suffix('.slides.html')\n",
    "                if os.path.exists(notebook_file):\n",
    "                    if not notebook_output.exists():\n",
    "                        os.system(f'jupyter nbconvert {notebook_file} --to slides --output-dir {str(notebook_output.parent)}')\n",
    "                    if notebook_output.exists():\n",
    "                        write_notebook = True\n",
    "                        f.write(f'  : [<span class=\"iconfont icon-jupyter\"></span>]({str(notebook_output)})\\n')\n",
    "            if not write_notebook:\n",
    "                f.write('  :  &nbsp; \\n')\n",
    "                    #if entry['notebook_video']:\n",
    "                    #    f.write(f' [<span style=\"font-size:130%\"  class=\"iconfont icon-bilibili-fill\"></span> 代码]({entry[\"notebook_video\"]}) &nbsp;')\n",
    "            #if 'qa_video' in entry and entry['qa_video']:\n",
    "            #   f.write(f' [<span style=\"font-size:130%\"  class=\"iconfont icon-bilibili-fill\"></span> 问答]({entry[\"qa_video\"]}) &nbsp;')\n",
    "            if entry['slides_video']:\n",
    "                f.write(f'  : [<span style=\"font-size:130%\"  class=\"iconfont icon-bilibili-fill\"></span>]({entry[\"slides_video\"]})\\n')\n",
    "            else:\n",
    "                f.write('  :  &nbsp; \\n')\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "!touch index.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
