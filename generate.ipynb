{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "legislative-radius",
   "metadata": {},
   "source": [
    "Generate `contents.json` based on the `d2l-zh` repos, then manually copy and modify to `_modelules/*.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "authorized-burton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:50:55.838647Z",
     "start_time": "2021-04-19T17:50:53.866026Z"
    }
   },
   "outputs": [],
   "source": [
    "import notedown\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "entry = '''    {\n",
    "        \"title\":\"TITLE\",\n",
    "        \"day_break\":false,\n",
    "        \"book\":\"URL\",\n",
    "        \"slides\":[\"part-0.pdf\",0],\n",
    "        \"slides_video\":\"\",\n",
    "        \"notebook_video\":\"\",\n",
    "        \"qa_video\":\"\"\n",
    "    }'''\n",
    "\n",
    "\n",
    "book_repo = pathlib.Path('/Users/mli/repos/d2l-en')\n",
    "\n",
    "def get_toc(root):\n",
    "    \"\"\"return a list of files in the order defined by TOC\"\"\"\n",
    "    subpages = _get_subpages(root)\n",
    "    res = [root]\n",
    "    for fn in subpages:\n",
    "        res.extend(get_toc(fn))\n",
    "    return res\n",
    "\n",
    "def _get_subpages(input_fn):\n",
    "    \"\"\"read toc in input_fn, returns what it contains\"\"\"\n",
    "    subpages = []\n",
    "    reader = notedown.MarkdownReader()\n",
    "    with open(input_fn, 'r', encoding='UTF-8') as f:\n",
    "        nb = reader.read(f)\n",
    "    for cell in nb.cells:\n",
    "        if (cell.cell_type == 'code' and 'attributes' in cell.metadata and\n",
    "                'toc' in cell.metadata.attributes['classes']):\n",
    "            for l in cell.source.split('\\n'):\n",
    "                l = l.strip()\n",
    "                if not l.startswith(':'):\n",
    "                    fn = os.path.join(os.path.dirname(input_fn), l + '.md')\n",
    "                    if os.path.exists(fn):\n",
    "                        subpages.append(fn)\n",
    "    return subpages\n",
    "\n",
    "def _get_title(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            if l.startswith('#'): return l[1:].strip()\n",
    "\n",
    "entries = []\n",
    "notebooks = get_toc(str(book_repo/'index.md'))\n",
    "for nb in notebooks:\n",
    "    p = str(pathlib.Path(nb).relative_to(book_repo).with_suffix('.html'))\n",
    "    if 'index.md' in p: continue\n",
    "    title = _get_title(nb)\n",
    "    if not title: continue\n",
    "    entries.append(entry.replace('TITLE', title).replace('URL', p))\n",
    "\n",
    "with open('contents.json', 'w') as f:\n",
    "    f.write('[\\n' + ',\\n'.join(entries) + '\\n]\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-committee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accessible-geneva",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:50:33.161828Z",
     "start_time": "2021-04-19T17:50:33.145379Z"
    }
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "import subprocess\n",
    "\n",
    "def extract_pdf(source, start_page, end_page, target):\n",
    "    source = pathlib.Path(source)\n",
    "    target = pathlib.Path(target)\n",
    "    if target.exists() and target.stat().st_mtime > source.stat().st_mtime:\n",
    "        return\n",
    "    pdf = PdfFileReader(str(source))\n",
    "    assert end_page > start_page\n",
    "    assert end_page <= pdf.getNumPages()\n",
    "    pdf_writer = PdfFileWriter()\n",
    "    for page in range(start_page, end_page):\n",
    "        pdf_writer.addPage(pdf.getPage(page))\n",
    "    with open('/tmp/tmp.pdf', 'wb') as out:\n",
    "        pdf_writer.write(out)\n",
    "    # compress pdf size\n",
    "    # refer to https://askubuntu.com/questions/113544/how-can-i-reduce-the-file-size-of-a-scanned-pdf-file\n",
    "    cmd = f'gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/prepress -dNOPAUSE  -dBATCH -sOutputFile={str(target)} /tmp/tmp.pdf'\n",
    "    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.PIPE)\n",
    "    stdout, _ = process.communicate()\n",
    "    if process.returncode != 0:\n",
    "        print(stdout.decode().splitlines())\n",
    "    print(f'Written {end_page-start_page} pages to {target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-settle",
   "metadata": {},
   "source": [
    "Generate all `_modules/part*.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "timely-ensemble",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:51:44.396187Z",
     "start_time": "2021-04-19T17:50:58.273423Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 2 pages to assets/pdfs/part-0_3.pdf\n",
      "Written 5 pages to assets/pdfs/part-0_4.pdf\n",
      "Written 14 pages to assets/pdfs/part-0_5.pdf\n",
      "Written 10 pages to assets/pdfs/part-0_6.pdf\n",
      "Written 15 pages to assets/pdfs/part-0_7.pdf\n",
      "Written 11 pages to assets/pdfs/part-0_8.pdf\n",
      "Written 6 pages to assets/pdfs/part-0_9.pdf\n",
      "Written 11 pages to assets/pdfs/part-0_10.pdf\n",
      "Written 7 pages to assets/pdfs/part-0_11.pdf\n",
      "Written 11 pages to assets/pdfs/part-0_12.pdf\n",
      "Written 13 pages to assets/pdfs/part-0_13.pdf\n",
      "Written 7 pages to assets/pdfs/part-0_14.pdf\n",
      "Written 10 pages to assets/pdfs/part-0_15.pdf\n",
      "Written 6 pages to assets/pdfs/part-0_16.pdf\n",
      "Written 6 pages to assets/pdfs/part-0_17.pdf\n",
      "Written 10 pages to assets/pdfs/part-0_18.pdf\n",
      "Written 12 pages to assets/pdfs/part-0_19.pdf\n",
      "Written 2 pages to assets/pdfs/part-0_20.pdf\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "pdf_dir = '/Users/mli/Google Drive/d2l-zh-v2-slides/'\n",
    "slides_dir = 'assets/pdfs/'\n",
    "notebooks_dir = 'assets/notebooks/'\n",
    "book_url = 'https://zh-v2.d2l.ai/'\n",
    "notebook_url = 'https://nbviewer.jupyter.org/format/slides/github/d2l-ai/d2l-zh-pytorch-slides/blob/main/'\n",
    "notbook_repo = '../d2l-zh-pytorch-slides/'\n",
    "video_url = 'https://www.bilibili.com/video/'\n",
    "cur_day = datetime.datetime(2021, 3, 19)\n",
    "\n",
    "titles = ['深度学习基础', '卷积神经网络', '计算机视觉', '优化算法','循环神经网络', '注意力机制', '自然语言处理']\n",
    "holidays = [datetime.datetime(2021, m, d) for m, d in ((4,3),(4,4),(5,1),(5,2),(6,12),(6,13))]\n",
    "slide_pages = {}\n",
    "\n",
    "for i, title in enumerate(titles):\n",
    "    p = pathlib.Path('_modules')\n",
    "    with (p/f'part_{i}.md').open('w') as f:\n",
    "        f.write(f'---\\ntitle: {title}\\n---\\n')\n",
    "        if not (p/f'part_{i}.json').exists():\n",
    "            contents = []\n",
    "        else:\n",
    "            contents = json.load((p/f'part_{i}.json').open('r'))\n",
    "        for entry in contents:\n",
    "            if entry['day_break']:\n",
    "                while True:\n",
    "                    if cur_day.weekday() == 6: # sun\n",
    "                        cur_day += datetime.timedelta(days=6)\n",
    "                    else:\n",
    "                        cur_day += datetime.timedelta(days=1)\n",
    "                    f.write(f'\\n{cur_day.month}月{cur_day.day}日\\n\\n')\n",
    "                    if cur_day not in holidays:\n",
    "                        break\n",
    "                    f.write(': **长假无课**{: .label .label-green }\\n')\n",
    "            # title\n",
    "            f.write(f': {entry[\"title\"]}\\n')\n",
    "            # html page\n",
    "            if 'book' in entry and entry['book']:\n",
    "                f.write(f'  : [<span class=\"iconfont icon-xiaoshuo-copy\"></span>]({book_url+entry[\"book\"]})\\n')\n",
    "            else:\n",
    "                f.write('  : &nbsp; \\n')\n",
    "            # pdf\n",
    "            pdf, page = entry['slides']\n",
    "            if page:\n",
    "                if pdf not in slide_pages:\n",
    "                    slide_pages[pdf] = [0,]\n",
    "                save_pdf = f'{slides_dir}part-{i}_{len(slide_pages[pdf])}.pdf'\n",
    "                cur_page = sum(slide_pages[pdf])\n",
    "                extract_pdf(pdf_dir+pdf, cur_page, cur_page+page, save_pdf)\n",
    "                slide_pages[pdf].append(page)\n",
    "                f.write(f'  : [<span class=\"iconfont icon-KeynoteOutline\"></span>]({save_pdf})\\n')\n",
    "            else:\n",
    "                f.write('  : &nbsp; \\n')\n",
    "\n",
    "            # notebook\n",
    "            write_notebook = False\n",
    "            if 'book' in entry and entry['book'] and  (not 'notebook' in  entry or entry['notebook']):\n",
    "                notebook_path = entry[\"book\"].replace('.html', '.ipynb')\n",
    "                notebook_file = notbook_repo + notebook_path\n",
    "                notebook_output = pathlib.Path(notebooks_dir + notebook_path).with_suffix('.slides.html')\n",
    "                if os.path.exists(notebook_file):\n",
    "                    if not notebook_output.exists():\n",
    "                        os.system(f'jupyter nbconvert {notebook_file} --to slides --output-dir {str(notebook_output.parent)}')\n",
    "                    if notebook_output.exists():\n",
    "                        write_notebook = True\n",
    "                        f.write(f'  : [<span class=\"iconfont icon-jupyter\"></span>]({str(notebook_output)})\\n')\n",
    "            if not write_notebook:\n",
    "                f.write('  :  &nbsp; \\n')\n",
    "                    #if entry['notebook_video']:\n",
    "                    #    f.write(f' [<span style=\"font-size:130%\"  class=\"iconfont icon-bilibili-fill\"></span> 代码]({entry[\"notebook_video\"]}) &nbsp;')\n",
    "            #if 'qa_video' in entry and entry['qa_video']:\n",
    "            #   f.write(f' [<span style=\"font-size:130%\"  class=\"iconfont icon-bilibili-fill\"></span> 问答]({entry[\"qa_video\"]}) &nbsp;')\n",
    "            if entry['slides_video']:\n",
    "                f.write(f'  : [<span style=\"font-size:130%\"  class=\"iconfont icon-bilibili-fill\"></span>]({entry[\"slides_video\"]})\\n')\n",
    "            else:\n",
    "                f.write('  :  &nbsp; \\n')\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "!touch index.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-ownership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-locking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
