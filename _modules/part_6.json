[
    {
        "title":"Natural Language Processing: Pretraining",
        "day_break":true,
        "book":"chapter_natural-language-processing-pretraining/index.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Word Embedding (word2vec)",
        "day_break":false,
        "book":"chapter_natural-language-processing-pretraining/word2vec.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Approximate Training",
        "day_break":false,
        "book":"chapter_natural-language-processing-pretraining/approx-training.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"The Dataset for Pretraining Word Embedding",
        "day_break":false,
        "book":"chapter_natural-language-processing-pretraining/word-embedding-dataset.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Pretraining word2vec",
        "day_break":true,
        "book":"chapter_natural-language-processing-pretraining/word2vec-pretraining.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Word Embedding with Global Vectors (GloVe)",
        "day_break":false,
        "book":"chapter_natural-language-processing-pretraining/glove.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Subword Embedding",
        "day_break":false,
        "book":"chapter_natural-language-processing-pretraining/subword-embedding.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Finding Synonyms and Analogies",
        "day_break":false,
        "book":"chapter_natural-language-processing-pretraining/similarity-analogy.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Bidirectional Encoder Representations from Transformers (BERT)",
        "day_break":true,
        "book":"chapter_natural-language-processing-pretraining/bert.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"The Dataset for Pretraining BERT",
        "day_break":false,
        "book":"chapter_natural-language-processing-pretraining/bert-dataset.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Pretraining BERT",
        "day_break":false,
        "book":"chapter_natural-language-processing-pretraining/bert-pretraining.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Natural Language Processing: Applications",
        "day_break":false,
        "book":"chapter_natural-language-processing-applications/index.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Sentiment Analysis and the Dataset",
        "day_break":true,
        "book":"chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Sentiment Analysis: Using Recurrent Neural Networks",
        "day_break":false,
        "book":"chapter_natural-language-processing-applications/sentiment-analysis-rnn.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Sentiment Analysis: Using Convolutional Neural Networks",
        "day_break":false,
        "book":"chapter_natural-language-processing-applications/sentiment-analysis-cnn.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Natural Language Inference and the Dataset",
        "day_break":false,
        "book":"chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Natural Language Inference: Using Attention",
        "day_break":true,
        "book":"chapter_natural-language-processing-applications/natural-language-inference-attention.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Fine-Tuning BERT for Sequence-Level and Token-Level Applications",
        "day_break":false,
        "book":"chapter_natural-language-processing-applications/finetuning-bert.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    },
    {
        "title":"Natural Language Inference: Fine-Tuning BERT",
        "day_break":false,
        "book":"chapter_natural-language-processing-applications/natural-language-inference-bert.html",
        "slides":["part-0.pdf",0],
        "slides_video":"",
        "notebook_video":"",
        "tag":""
    }
]