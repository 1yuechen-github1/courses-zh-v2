---
title: 自然语言处理
---

6月19日

: Natural Language Processing: Pretraining
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/index.html)

: Word Embedding (word2vec)
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/word2vec.html)

: Approximate Training
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/approx-training.html)

: The Dataset for Pretraining Word Embedding
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/word-embedding-dataset.html)


6月20日

: Pretraining word2vec
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/word2vec-pretraining.html)

: Word Embedding with Global Vectors (GloVe)
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/glove.html)

: Subword Embedding
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/subword-embedding.html)

: Finding Synonyms and Analogies
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/similarity-analogy.html)


6月26日

: Bidirectional Encoder Representations from Transformers (BERT)
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/bert.html)

: The Dataset for Pretraining BERT
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/bert-dataset.html)

: Pretraining BERT
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/bert-pretraining.html)

: Natural Language Processing: Applications
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/index.html)


6月27日

: Sentiment Analysis and the Dataset
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html)

: Sentiment Analysis: Using Recurrent Neural Networks
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/sentiment-analysis-rnn.html)

: Sentiment Analysis: Using Convolutional Neural Networks
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/sentiment-analysis-cnn.html)

: Natural Language Inference and the Dataset
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html)


7月3日

: Natural Language Inference: Using Attention
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-attention.html)

: Fine-Tuning BERT for Sequence-Level and Token-Level Applications
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/finetuning-bert.html)

: Natural Language Inference: Fine-Tuning BERT
  : [<span class="iconfont icon-xiaoshuo-copy"></span>](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-bert.html)

