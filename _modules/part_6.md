---
title: 自然语言处理
---

7月10日

: Natural Language Processing: Pretraining
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/index.html) &nbsp;
: Word Embedding (word2vec)
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/word2vec.html) &nbsp;
: Approximate Training
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/approx-training.html) &nbsp;
: The Dataset for Pretraining Word Embedding
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/word-embedding-dataset.html) &nbsp;

7月11日

: Pretraining word2vec
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/word2vec-pretraining.html) &nbsp;
: Word Embedding with Global Vectors (GloVe)
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/glove.html) &nbsp;
: Subword Embedding
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/subword-embedding.html) &nbsp;
: Finding Synonyms and Analogies
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/similarity-analogy.html) &nbsp;

7月17日

: Bidirectional Encoder Representations from Transformers (BERT)
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/bert.html) &nbsp;
: The Dataset for Pretraining BERT
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/bert-dataset.html) &nbsp;
: Pretraining BERT
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-pretraining/bert-pretraining.html) &nbsp;
: Natural Language Processing: Applications
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/index.html) &nbsp;

7月18日

: Sentiment Analysis and the Dataset
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html) &nbsp;
: Sentiment Analysis: Using Recurrent Neural Networks
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/sentiment-analysis-rnn.html) &nbsp;
: Sentiment Analysis: Using Convolutional Neural Networks
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/sentiment-analysis-cnn.html) &nbsp;
: Natural Language Inference and the Dataset
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html) &nbsp;

7月24日

: Natural Language Inference: Using Attention
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-attention.html) &nbsp;
: Fine-Tuning BERT for Sequence-Level and Token-Level Applications
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/finetuning-bert.html) &nbsp;
: Natural Language Inference: Fine-Tuning BERT
  : [<span class="iconfont icon-xiaoshuo-copy"></span> 书](https://zh-v2.d2l.ai/chapter_natural-language-processing-applications/natural-language-inference-bert.html) &nbsp;
